{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./kaggle_data/train.csv')\n",
    "weather_df = pd.read_csv('./kaggle_data/weather.csv')\n",
    "spray_df = pd.read_csv('./kaggle_data/spray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Address</th>\n",
       "      <th>Species</th>\n",
       "      <th>Block</th>\n",
       "      <th>Street</th>\n",
       "      <th>Trap</th>\n",
       "      <th>AddressNumberAndStreet</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>AddressAccuracy</th>\n",
       "      <th>NumMosquitos</th>\n",
       "      <th>WnvPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.954690</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.954690</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>6200 North Mandell Avenue, Chicago, IL 60646, USA</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>62</td>\n",
       "      <td>N MANDELL AVE</td>\n",
       "      <td>T007</td>\n",
       "      <td>6200  N MANDELL AVE, Chicago, IL</td>\n",
       "      <td>41.994991</td>\n",
       "      <td>-87.769279</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>7900 West Foster Avenue, Chicago, IL 60656, USA</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>79</td>\n",
       "      <td>W FOSTER AVE</td>\n",
       "      <td>T015</td>\n",
       "      <td>7900  W FOSTER AVE, Chicago, IL</td>\n",
       "      <td>41.974089</td>\n",
       "      <td>-87.824812</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>7900 West Foster Avenue, Chicago, IL 60656, USA</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>79</td>\n",
       "      <td>W FOSTER AVE</td>\n",
       "      <td>T015</td>\n",
       "      <td>7900  W FOSTER AVE, Chicago, IL</td>\n",
       "      <td>41.974089</td>\n",
       "      <td>-87.824812</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                            Address  \\\n",
       "0  2007-05-29  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "1  2007-05-29  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "2  2007-05-29  6200 North Mandell Avenue, Chicago, IL 60646, USA   \n",
       "3  2007-05-29    7900 West Foster Avenue, Chicago, IL 60656, USA   \n",
       "4  2007-05-29    7900 West Foster Avenue, Chicago, IL 60656, USA   \n",
       "\n",
       "                  Species  Block           Street  Trap  \\\n",
       "0  CULEX PIPIENS/RESTUANS     41   N OAK PARK AVE  T002   \n",
       "1          CULEX RESTUANS     41   N OAK PARK AVE  T002   \n",
       "2          CULEX RESTUANS     62    N MANDELL AVE  T007   \n",
       "3  CULEX PIPIENS/RESTUANS     79     W FOSTER AVE  T015   \n",
       "4          CULEX RESTUANS     79     W FOSTER AVE  T015   \n",
       "\n",
       "              AddressNumberAndStreet   Latitude  Longitude  AddressAccuracy  \\\n",
       "0  4100  N OAK PARK AVE, Chicago, IL  41.954690 -87.800991                9   \n",
       "1  4100  N OAK PARK AVE, Chicago, IL  41.954690 -87.800991                9   \n",
       "2   6200  N MANDELL AVE, Chicago, IL  41.994991 -87.769279                9   \n",
       "3    7900  W FOSTER AVE, Chicago, IL  41.974089 -87.824812                8   \n",
       "4    7900  W FOSTER AVE, Chicago, IL  41.974089 -87.824812                8   \n",
       "\n",
       "   NumMosquitos  WnvPresent  \n",
       "0             1           0  \n",
       "1             1           0  \n",
       "2             1           0  \n",
       "3             1           0  \n",
       "4             4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Depart</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>...</th>\n",
       "      <th>CodeSum</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Water1</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>StnPressure</th>\n",
       "      <th>SeaLevel</th>\n",
       "      <th>ResultSpeed</th>\n",
       "      <th>ResultDir</th>\n",
       "      <th>AvgSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>83</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.10</td>\n",
       "      <td>29.82</td>\n",
       "      <td>1.7</td>\n",
       "      <td>27</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>84</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.82</td>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>-3</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.38</td>\n",
       "      <td>30.09</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>BR HZ</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.44</td>\n",
       "      <td>30.08</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.12</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station        Date  Tmax  Tmin Tavg Depart  DewPoint WetBulb Heat Cool  \\\n",
       "0        1  2007-05-01    83    50   67     14        51      56    0    2   \n",
       "1        2  2007-05-01    84    52   68      M        51      57    0    3   \n",
       "2        1  2007-05-02    59    42   51     -3        42      47   14    0   \n",
       "3        2  2007-05-02    60    43   52      M        42      47   13    0   \n",
       "4        1  2007-05-03    66    46   56      2        40      48    9    0   \n",
       "\n",
       "     ...    CodeSum Depth Water1 SnowFall PrecipTotal StnPressure SeaLevel  \\\n",
       "0    ...                0      M      0.0        0.00       29.10    29.82   \n",
       "1    ...                M      M        M        0.00       29.18    29.82   \n",
       "2    ...         BR     0      M      0.0        0.00       29.38    30.09   \n",
       "3    ...      BR HZ     M      M        M        0.00       29.44    30.08   \n",
       "4    ...                0      M      0.0        0.00       29.39    30.12   \n",
       "\n",
       "  ResultSpeed ResultDir  AvgSpeed  \n",
       "0         1.7        27       9.2  \n",
       "1         2.7        25       9.6  \n",
       "2        13.0         4      13.4  \n",
       "3        13.3         2      13.4  \n",
       "4        11.7         7      11.9  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to better understand `spray_df` and identify where weather stations 1 and 2 are.  All dataframes include date data, so the next step is to figure out how to appropriately combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(train_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the likelihood of WNV increases as the number of mosquitos increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_df.shape)\n",
    "#train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(spray_df.shape)\n",
    "#spray_df.isnull().sum()\n",
    "                 ## We will need to deal with these time nulls, but it may make sense to drop the time column\n",
    "                  # since the other dfs dont have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(spray_df.shape)\n",
    "#weather_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spray_df.drop('Time', axis = 1, inplace = True) # dropping time from spray data because it is not in any other dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spray_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather = weather_df[weather_df['Station'] == 1] # creating weather data df using only one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "daily_weather.drop('Station', axis= 1, inplace=True) # dropping station label since all are station 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "daily_weather.reset_index(inplace=True, drop=True) \n",
    "\n",
    "daily_weather['Date'] = pd.to_datetime(daily_weather['Date']) \n",
    "\n",
    "daily_weather.set_index('Date',inplace=True, drop=True) # datetime index on weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date'] = pd.to_datetime(train_df['Date']) #datetime index on training data\n",
    "\n",
    "train_df.set_index('Date', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(train_df, \n",
    "                  daily_weather, \n",
    "                  left_on = train_df.index, right_on = daily_weather.index) #new_df = combined weather and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.shape, train_df.shape, weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['key_0'] = pd.to_datetime(new_df['key_0'])\n",
    "\n",
    "new_df.set_index('key_0', inplace=True, drop=True)\n",
    "\n",
    "new_df.index.rename('Date', inplace=True) #assiging date as index of new_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(['Water1','SnowFall'], axis=1, inplace=True) # dropping these columns since they provided no info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_precip = float(new_df[new_df['PrecipTotal'] != '  T'].StnPressure.mode()[0]) # storing mode precip value for replacement in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_totals = []\n",
    "for total in new_df.PrecipTotal:\n",
    "    if total == '  T':\n",
    "        precip_totals.append(mode_precip)\n",
    "    else:\n",
    "        precip_totals.append(total)\n",
    "\n",
    "new_df.PrecipTotal = pd.to_numeric(precip_totals) # replacing '  T' with mode precip value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_pressure = new_df[new_df['StnPressure'] != 'M'].StnPressure.mode() # storing mode pressure for replacement in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressures = []\n",
    "for pressure in new_df.StnPressure:\n",
    "    if pressure == 'M':\n",
    "        pressures.append(mode_pressure)\n",
    "    else:\n",
    "        pressures.append(pressure)\n",
    "pressures = [float(pressure) for pressure in pressures]\n",
    "\n",
    "new_df.StnPressure = pd.to_numeric(pressures) # replacing 'M' with mode pressure value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressures = [float(pressure) for pressure in pressures] # converting strings to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.dtypes\n",
    "cols_to_change = ['Tavg',\n",
    "                 'Depart',\n",
    "                 'Cool',\n",
    "                 'Sunrise',\n",
    "                 'Sunset',\n",
    "                 'Depth',\n",
    "                 'PrecipTotal',\n",
    "                 'StnPressure',\n",
    "                 'SeaLevel',\n",
    "                 'AvgSpeed'\n",
    "                 ] # columns of type object that can be coerced to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_change:\n",
    "    new_df[col] = pd.to_numeric(new_df[col])#changing columns above to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnv1_df = new_df[new_df['WnvPresent'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnv0_df = new_df[new_df['WnvPresent'] == 0].sample(n = wnv1_df.shape[0], random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([wnv1_df, wnv0_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = num_df.drop('WnvPresent', axis = 1)\n",
    "y = num_df.WnvPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = pca.transform(X_train)\n",
    "Z_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest on Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 4, 'n_estimators': 20, 'random_state': 31}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "rf_params = {'n_estimators':[8,10,12,14,20],\n",
    "            'min_samples_split':[2,3,4],\n",
    "            'random_state':[1,21,31,100]}\n",
    "rf_gs = GridSearchCV(rf, rf_params, n_jobs=4)\n",
    "rf_gs.fit(Z_train, y_train)\n",
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rf_gs.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7702702702702703, 0.7427536231884058)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, rf_preds), accuracy_score(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost on Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'n_estimators': [30, 40, 50, 60, 80], 'learning_rate': [0.8, 0.4, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada_params = {'n_estimators':[30,40,50,60,80],\n",
    "             'learning_rate':[.8,.4,.1],}\n",
    "ada_gs = GridSearchCV(ada, ada_params, n_jobs=4)\n",
    "ada_gs.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_preds = ada_gs.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.4, 'n_estimators': 60}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7283950617283951, 0.7210144927536232)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, ada_preds), accuracy_score(y_test, ada_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost on Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5], 'n_estimators': [50, 80, 100, 120], 'min_samples_split': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = GradientBoostingClassifier()\n",
    "xgb_params = {'learning_rate':[.01, .05, .1, .3, .5],\n",
    "             'n_estimators':[50,80, 100, 120],\n",
    "             'min_samples_split':[2,3,4]}\n",
    "xgb_gs = GridSearchCV(xgb, xgb_params, n_jobs=4)\n",
    "xgb_gs.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'min_samples_split': 4, 'n_estimators': 100}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgb_gs.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.7427536231884058)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, xgb_preds), accuracy_score(y_test, xgb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying same three models on dummied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Address', 'Species', 'Block', 'Street', 'Trap',\n",
       "       'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy',\n",
       "       'NumMosquitos', 'WnvPresent', 'Tmax', 'Tmin', 'Tavg', 'Depart',\n",
       "       'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset', 'CodeSum',\n",
       "       'Depth', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
       "       'ResultDir', 'AvgSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df = pd.get_dummies(df.drop(['Address','Street'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dum = dummies_df.drop('WnvPresent', axis = 1)\n",
    "y = dummies_df.WnvPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdum_train, Xdum_test, ydum_train, ydum_test = train_test_split(X_dum, y, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_dum = StandardScaler()\n",
    "ss_dum.fit(Xdum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdum_train = ss_dum.transform(Xdum_train)\n",
    "Xdum_test = ss_dum.transform(Xdum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dum = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dum.fit(Xdum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zdum_train = pca_dum.transform(Xdum_train)\n",
    "Zdum_test = pca_dum.transform(Xdum_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest on Dummy Data\n",
    "### Random forest had highest accuracy of 78.6% but lower precision than AdaBoost using just numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 2, 'n_estimators': 20, 'random_state': 1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_dum = RandomForestClassifier(n_jobs=4)\n",
    "rf_params = {'n_estimators':[8,10,12,14,20],\n",
    "            'min_samples_split':[2,3,4],\n",
    "            'random_state':[1,21,31,100]}\n",
    "rf_dum_gs = GridSearchCV(rf_dum, rf_params, n_jobs=4)\n",
    "rf_dum_gs.fit(Zdum_train, ydum_train)\n",
    "rf_dum_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dum_preds = rf_dum_gs.predict(Zdum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6910569105691057, 0.6666666666666666)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ydum_test, rf_dum_preds), accuracy_score(ydum_test, rf_dum_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost on Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'n_estimators': [30, 40, 50, 60, 80], 'learning_rate': [0.8, 0.4, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_dum = AdaBoostClassifier()\n",
    "ada_dum_params = {'n_estimators':[30,40,50,60,80],\n",
    "             'learning_rate':[.8,.4,.1],}\n",
    "ada_dum_gs = GridSearchCV(ada_dum, ada_params, n_jobs=4)\n",
    "ada_dum_gs.fit(Zdum_train, ydum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_dum_preds = ada_dum_gs.predict(Zdum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.8, 'n_estimators': 40}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_dum_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6808510638297872, 0.6811594202898551)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ydum_test, ada_dum_preds), accuracy_score(ydum_test, ada_dum_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost on Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5], 'n_estimators': [50, 80, 100, 120]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_dum = GradientBoostingClassifier()\n",
    "xgb_dum_params = {'learning_rate':[.01, .05, .1, .3, .5],\n",
    "             'n_estimators':[50,80, 100, 120]}\n",
    "xgb_dum_gs = GridSearchCV(xgb_dum, xgb_dum_params, n_jobs=4)\n",
    "xgb_dum_gs.fit(Zdum_train, ydum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'n_estimators': 100}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_dum_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_dum_preds = xgb_dum_gs.predict(Zdum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7007299270072993, 0.6956521739130435)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ydum_test, xgb_dum_preds), accuracy_score(ydum_test, xgb_dum_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suzanne Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'lr__C': 0.5, 'lr__penalty': 'l1'}\n",
      "Best Train Score: 0.7330623306233063\n",
      "Best Test Score: 0.7472527472527473\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = ['WnvPresent', 'Address', \n",
    "                           'Species', 'Street', 'Trap', \n",
    "                           'AddressNumberAndStreet', 'WetBulb'\n",
    "                           , 'Heat', 'CodeSum'],\n",
    "                            axis = 1)\n",
    "y = df['WnvPresent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size = 0.33, \n",
    "                                                   random_state = 42)\n",
    "\n",
    "# Instantiating Preprocessing and Model \n",
    "lr = LogisticRegression()\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Setting up Pipeline \n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "# Setting up Parameter Dictionary \n",
    "gs_lr_params = {\n",
    "    'lr__penalty': ['l1', 'l2'], \n",
    "    'lr__C': [0.5, 1.0, 1.2]\n",
    "}\n",
    "\n",
    "# Instantiating and Fitting my Grid Search\n",
    "gs_lr = GridSearchCV(lr_pipe, param_grid=gs_lr_params)\n",
    "gs_lr.fit(X_train, y_train);\n",
    "\n",
    "print(\"Best Params:\", gs_lr.best_params_)\n",
    "print(\"Best Train Score:\", gs_lr.best_score_ )\n",
    "print(\"Best Test Score:\", gs_lr.score(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
